{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices: Advanced Regression Techniques, Part 1\n",
    "## Load, explore, and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "pd.options.display.precision = 4\n",
    "mpl.rcParams['font.family'] = 'Lato'\n",
    "mpl.rcParams['font.weight'] = 700\n",
    "sns.set(font='Lato', font_scale=1)\n",
    "sns.set()\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n",
    "\n",
    "With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is split across three tables:\n",
    "\n",
    "- `listing_training`\n",
    "- `zoning`\n",
    "- `sale`\n",
    "\n",
    "Load the data from these tables:\n",
    "1. connect to the database using `psycopg2`\n",
    "1. use a `psycopg2.extras.RealDictCursor` so that you get the columns names returned with your query\n",
    "1. pull the data using a `SELECT` `JOIN` statement \n",
    "1. you should be able to join all tables using `id`\n",
    "1. load the result into a `pandas.DataFrame`\n",
    "1. use `id` as the index for your DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "could not connect to server: Connection refused\n\tIs the server running on host \"michaelgfrantz.com\" (162.243.140.117) and accepting\n\tTCP/IP connections on port 5432?\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fc727f576f27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m conn = pg2.connect(host = this_host, \n\u001b[1;32m      9\u001b[0m                         \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_user\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                         password = this_password)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mcurs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcursor_factory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpgex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRealDictCursor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#execute SQL query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/psycopg2/__init__.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(dsn, database, user, password, host, port, connection_factory, cursor_factory, async, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 for (k, v) in items])\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_factory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_factory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcursor_factory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcursor_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: could not connect to server: Connection refused\n\tIs the server running on host \"michaelgfrantz.com\" (162.243.140.117) and accepting\n\tTCP/IP connections on port 5432?\n"
     ]
    }
   ],
   "source": [
    "import psycopg2 as pg2\n",
    "import psycopg2.extras as pgex\n",
    "\n",
    "this_host='michaelgfrantz.com'\n",
    "this_user='postgres'\n",
    "this_password='dsism4'\n",
    "\n",
    "conn = pg2.connect(host = this_host, \n",
    "                        user = this_user,\n",
    "                        password = this_password)\n",
    "curs = conn.cursor(cursor_factory=pgex.RealDictCursor)\n",
    "#execute SQL query\n",
    "query = \"\"\"  select * \n",
    "            from listing_training l\n",
    "            join zoning z on l.id = z.id\n",
    "            join sale s on l.id = s.id;\n",
    "\"\"\"\n",
    "curs.execute(query)\n",
    "results = curs.fetchall()\n",
    "conn.close()\n",
    "houseprice_df = pd.DataFrame(results)\n",
    "houseprice_df.set_index('id',drop=True, inplace = True)\n",
    "houseprice_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "houseprice_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the names of the columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "houseprice_df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all the columns with over 500 null values\n",
    "\n",
    "Use Python to find and drop these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(houseprice_df['alley'].isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_500null = []\n",
    "houseprice_df_cleaning = houseprice_df.copy()\n",
    "for col in houseprice_df.columns:\n",
    "    if sum(houseprice_df[col].isnull()) > 500:\n",
    "        houseprice_df_cleaning.drop(col,axis =1, inplace=True)\n",
    "        column_500null.append(col)\n",
    "column_500null\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many columns of each data type are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_type={}\n",
    "for col in houseprice_df_cleaning.columns:\n",
    "    key = houseprice_df_cleaning[col].dtype\n",
    "    if key in data_type:\n",
    "        data_type[key] += 1\n",
    "    else: \n",
    "        data_type[key] = 1\n",
    "data_type        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "houseprice_df_cleaning.get_dtype_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Meta-Information DataFrame\n",
    "\n",
    "1. call it `feature_info_df`\n",
    "1. make an empty list called `feature_info`\n",
    "1. for each column make a dictionary:  \n",
    "   `{'feature':<column_name>,  \n",
    "    'n_unique': <number_of_unique_elements>,  \n",
    "    'datatype': <datatype_of_the_feature>}`\n",
    "1. append the dictionary to the list `feature_info`\n",
    "1. use the list of dictionaries to create a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_info_df = houseprice_df_cleaning.copy()\n",
    "feature_info = []\n",
    "for col in feature_info_df.columns:\n",
    "    info = { \n",
    "        'feature': col,\n",
    "        'n_unique': len(set(feature_info_df[col])),\n",
    "        'datatype': feature_info_df[col].dtype\n",
    "    }\n",
    "    feature_info.append(info)\n",
    "feature_info_df = pd.DataFrame(feature_info)  \n",
    "feature_info_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the meta information for all of the integers columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_info_int_df = feature_info_df[feature_info_df['datatype']=='int64']\n",
    "feature_info_int_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the meta-info dataframe to find all the integer features with 15 or less unique values\n",
    "\n",
    "Make a list of these columns. We will change the type of these features to 'object' in our original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "object_list = []\n",
    "for i in range(0,len(feature_info_int_df)):\n",
    "   \n",
    "    if feature_info_int_df['n_unique'].iloc[i] <15:\n",
    "        object_list.append(feature_info_int_df['feature'].iloc[i])\n",
    "object_list        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the type of these features in your original dataframe to be `object` \n",
    "We will be treating these as categorical variables.\n",
    "\n",
    "Change the datatype for each feature in your main dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in houseprice_df_cleaning.columns:\n",
    "    if col in object_list:\n",
    "        houseprice_df_cleaning[col] = houseprice_df_cleaning[col].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update your meta-info dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_info_df2 = houseprice_df_cleaning.copy()\n",
    "feature_info_2 = []\n",
    "for col in feature_info_df2.columns:\n",
    "    info = { \n",
    "        'feature': col,\n",
    "        'n_unique': len(set(feature_info_df2[col])),\n",
    "        'datatype': feature_info_df2[col].dtype\n",
    "    }\n",
    "    feature_info_2.append(info)\n",
    "feature_info_df2 = pd.DataFrame(feature_info_2)  \n",
    "feature_info_df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many columns of each data type are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_type={}\n",
    "for col in houseprice_df_cleaning.columns:\n",
    "    key = houseprice_df_cleaning[col].dtype\n",
    "    if key in data_type:\n",
    "        data_type[key] += 1\n",
    "    else: \n",
    "        data_type[key] = 1\n",
    "data_type     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the remaining integer columns to float columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in houseprice_df_cleaning.columns:\n",
    "    if houseprice_df_cleaning[col].dtype =='int64':\n",
    "        houseprice_df_cleaning[col]= houseprice_df_cleaning[col].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many columns of each data type are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_type={}\n",
    "for col in houseprice_df_cleaning.columns:\n",
    "    key = houseprice_df_cleaning[col].dtype\n",
    "    if key in data_type:\n",
    "        data_type[key] += 1\n",
    "    else: \n",
    "        data_type[key] = 1\n",
    "data_type    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create numerical and categorical dataframes\n",
    "\n",
    "Display the shapes of these dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_df = houseprice_df_cleaning.copy()\n",
    "cat_df = houseprice_df_cleaning.copy()\n",
    "for col in num_df.columns:\n",
    "    if num_df[col].dtype == 'O':\n",
    "        num_df=num_df.drop(col, axis = 1)\n",
    "        \n",
    "for col in cat_df.columns:\n",
    "    if cat_df[col].dtype == 'float64':\n",
    "        cat_df=cat_df.drop(col, axis = 1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the features with nans in the numerical dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_null_list = []\n",
    "for col in num_df.columns:\n",
    "    if sum(num_df[col].isnull()) > 0:\n",
    "        num_null_list.append(col)\n",
    "        print(col,sum(num_df[col].isnull()))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace the null rows for these features with either the mean or the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in num_null_list:\n",
    "    print('mean: ',num_df[col].mean())\n",
    "    print('median: ', num_df[col].median())\n",
    "    num_df[col] = num_df[col].where(num_df[col].isnull() == False,num_df[col].mean())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use subplots to display distribution plots of all numerical features\n",
    "Include the mean, median, and mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6,4)\n",
    "axes = axes.flatten()\n",
    "fig.set_size_inches(20, 30)\n",
    "fig.suptitle('Distribution of Numeric Features')\n",
    "for i, col in enumerate(num_df.columns):\n",
    "    feature = num_df[col]\n",
    "    sns.distplot(feature, label=col, ax=axes[i])\n",
    "    axes[i].axvline(feature.mean(),linewidth=1)\n",
    "    axes[i].axvline(feature.median(),linewidth=1, color='r')\n",
    "    axes[i].axvline(feature.mode().values[0],linewidth=1, color='g')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `df.skew` to find the skew of the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skew, skewtest, normaltest\n",
    "for col in num_df.columns:\n",
    "    print(col,' P_Value: ', skewtest(num_df[col]).pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a list of all features for which the absolute value of the skew is > 0.75\n",
    "\n",
    "These will need to be deskewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skew, skewtest, normaltest\n",
    "skewed_list = []\n",
    "for col in num_df.columns:\n",
    "    if abs(skew(num_df[col])) > 0.75:\n",
    "        skewed_list.append(col)\n",
    "print(skewed_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the skew for each of these features if we apply a simple log\n",
    "\n",
    "Either `np.log(feature)` or `np.log(1+feature)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simple_deskewed_num_df = num_df.copy()\n",
    "for col in skewed_list:\n",
    "    simple_deskewed_num_df[col] = np.log(1+ simple_deskewed_num_df[col])\n",
    "    \n",
    "skewed_list = {}\n",
    "for col in simple_deskewed_num_df.columns:\n",
    "    if abs(skew(simple_deskewed_num_df[col])) > 0.75:\n",
    "        ##print(col)\n",
    "        ##print(skew(simple_deskewed_num_df[col]))\n",
    "        ##print(simple_deskewed_num_df[col])\n",
    "        skewed_list[col] = skew(simple_deskewed_num_df[col])\n",
    "        \n",
    "print(skewed_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Find the optimal skew for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "deskewed_df = deskew(houseprice_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "deskew_plot(houseprice_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use either a simple log or an optimal log to deskew the selected numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use subplots to display distribution plots of all numerical features\n",
    "Include the mean, median, and mode.\n",
    "\n",
    "How do your distributions compare to the previous plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(6,4)\n",
    "axes = axes.flatten()\n",
    "fig.set_size_inches(20, 30)\n",
    "fig.suptitle('Distribution of Numeric Features')\n",
    "for i, col in enumerate(simple_deskewed_num_df.columns):\n",
    "    feature = num_df[col]\n",
    "    sns.distplot(feature, label=col, ax=axes[i])\n",
    "    axes[i].axvline(feature.mean(),linewidth=1)\n",
    "    axes[i].axvline(feature.median(),linewidth=1, color='r')\n",
    "    axes[i].axvline(feature.mode().values[0],linewidth=1, color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the features with nans in the categorical dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_nan_count={}\n",
    "for col in cat_df.columns:\n",
    "    if sum(cat_df[col].isnull())> 0: \n",
    "        cat_nan_count[col] = sum(cat_df[col].isnull())\n",
    "   \n",
    "print(cat_nan_count)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many columns of each data type are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_type={}\n",
    "for col in cat_df.columns:\n",
    "    key = cat_df[col].dtype\n",
    "    if key in data_type:\n",
    "        data_type[key] += 1\n",
    "    else: \n",
    "        data_type[key] = 1\n",
    "data_type "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace the null rows for these features with the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_nan_count.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in cat_nan_count.keys():\n",
    "    cat_df[col] = cat_df[col].where(cat_df[col].isnull()== False, cat_df[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in cat_df.columns:\n",
    "    if any(cat_df[col].isnull()) == True:\n",
    "        print(col)\n",
    "print('no_null')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many columns of each data type are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_type={}\n",
    "for col in cat_df.columns:\n",
    "    key = cat_df[col].dtype\n",
    "    if key in data_type:\n",
    "        data_type[key] += 1\n",
    "    else: \n",
    "        data_type[key] = 1\n",
    "data_type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast the whole categorical dataframe as an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in cat_df.columns:\n",
    "    cat_df[col] = cat_df[col].astype('object')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dummy Variable Columns for all categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_df_dummies = pd.get_dummies(cat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the shape of the new categorical dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cat_df_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_df_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the processed numerical and categorical dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simple_deskewed_num_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deskewed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "houseprice_df_cleaned_deskewed = simple_deskewed_num_df.merge(cat_df_dummies, left_index=True, right_index=True)\n",
    "houseprice_df_cleaned_deskewed_alpha = deskewed_df.merge(cat_df_dummies, left_index=True, right_index=True)\n",
    "houseprice_df_cleaned = num_df.merge(cat_df_dummies, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there is a reason to deskew dummies then scale for lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abs(skew(deskewed_df)) < abs(skew(simple_deskewed_num_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign `saleprice` to target and the remaining columns to `features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_deskewed = houseprice_df_cleaned_deskewed['saleprice']\n",
    "features_deskewed =  houseprice_df_cleaned_deskewed.drop('saleprice', axis = 1)\n",
    "features_deskewed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = houseprice_df_cleaned['saleprice']\n",
    "features =  houseprice_df_cleaned.drop('saleprice', axis = 1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_deskewed_scaled_w_Alpha = houseprice_df_cleaned_deskewed_alpha['saleprice']\n",
    "features_deskewed_scaled_w_Alpha =  houseprice_df_cleaned_deskewed_alpha.drop('saleprice', axis = 1)\n",
    "display(features_deskewed_scaled_w_Alpha.shape)\n",
    "\n",
    "pickled_features_deskewed_scaled_w_Alpha = pd.DataFrame.to_pickle(features_deskewed_scaled_w_Alpha,'../pickled/pickled_features_deskewed_scaled_w_Alpha')\n",
    "pickled_target_deskewed_scaled_w_Alpha = pd.DataFrame.to_pickle(target_deskewed_scaled_w_Alpha,'../pickled/pickled_target_deskewed_scaled_w_Alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### pickle features and target dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##turn it into a binary and save into a pickle\n",
    "pickled_features_deskewed = pd.DataFrame.to_pickle(features_deskewed,'../pickled/pickled_features_deskewed')\n",
    "pickled_target_deskewed = pd.DataFrame.to_pickle(target_deskewed,'../pickled/pickled_target_deskewed')\n",
    "pickled_features = pd.DataFrame.to_pickle(features,'../pickled/pickled_features')\n",
    "pickled_target = pd.DataFrame.to_pickle(target,'../pickled/pickled_target')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_meta_info_df(df):\n",
    "    feature_info = []\n",
    "    for col in df.columns:\n",
    "        info = { \n",
    "            'feature': col,\n",
    "            'n_unique': len(set(df[col])),\n",
    "            'datatype': df[col].dtype\n",
    "        \n",
    "        }\n",
    "        feature_info.append(info)\n",
    "    feature_info_df = pd.DataFrame(feature_info)  \n",
    "    return feature_info_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_meta_info_df(houseprice_df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
